{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#le\n",
    "\n",
    "#read in spreadsheet of all members from https://github.com/unitedstates/congress-legislators\n",
    "all_data = pd.read_csv(\"legislators-current.csv\")\n",
    "\n",
    "\n",
    "#read in the partisan lean for states and districts from https://github.com/fivethirtyeight/data/tree/master/partisan-lean\n",
    "state_lean = pd.read_csv(\"fivethirtyeight_partisan_lean_STATES.csv\")\n",
    "\n",
    "district_lean = pd.read_csv(\"fivethirtyeight_partisan_lean_DISTRICTS.csv\")\n",
    "\n",
    "#list of the states to filter out non-voting members from PR and AS \n",
    "states = list(state_lean[\"abbreviation\"].values)\n",
    "\n",
    "#read in the twitter handles we collectedly manually\n",
    "twitter_handles = pd.read_csv(\"twitter_handles.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(all_data.columns.values).\n",
    "\n",
    "#re-order columns for ease of reading\n",
    "\n",
    "new_columns = ['full_name','gender', 'type', 'state', 'district', 'party', 'official_twitter', 'last_name', 'first_name', 'middle_name', 'suffix','url', 'address', 'phone', 'contact_form', 'rss_url', 'facebook', 'youtube', 'youtube_id', 'bioguide_id', 'thomas_id', 'opensecrets_id', 'lis_id', 'fec_ids', 'cspan_id', 'govtrack_id', 'votesmart_id', 'ballotpedia_id', 'washington_post_id', 'icpsr_id', 'wikipedia_id']\n",
    "all_data = all_data[new_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column for districts that has state and number\n",
    "all_data.insert(5, \"full_district\", 'NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the district labels to match the partisan lean data and change party names\n",
    "for index_label, row_series in all_data.iterrows():\n",
    "    #change party name\n",
    "    if all_data.at[index_label, 'party'] == 'Republican':\n",
    "        all_data.at[index_label, 'party'] = \"R\"\n",
    "    if all_data.at[index_label, 'party'] == 'Democrat':\n",
    "        all_data.at[index_label, 'party'] = \"D\"\n",
    "    \n",
    "    # we only do this part for the house\n",
    "    if all_data.at[index_label, 'type'] == 'rep':\n",
    "        # the spreadhsheet has at-large districts like alaska as 0th, but the 538 data has them as one so fix that\n",
    "        if row_series['district'] == 0:\n",
    "            all_data.at[index_label , 'full_district'] = row_series['state'] + \"-\" + str(1)\n",
    "        # For each row update the full_district\n",
    "        else:\n",
    "            all_data.at[index_label , 'full_district'] = row_series['state'] + \"-\" + str(row_series['district'])[:-2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert the columns for partisan lean for 2018 [9] and 2020 [10] and personal twitter [7]\n",
    "\n",
    "all_data.insert(7, \"personal_twitter\", 'NaN')\n",
    "all_data.insert(9, \"partisan_lean_2018\", 'NaN')\n",
    "all_data.insert(10, \"partisan_lean_2020\", 'NaN')\n",
    "#all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index_label, row_series in all_data.iterrows():\n",
    "    #senators use state lean\n",
    "    if all_data.at[index_label, 'type'] == 'sen':\n",
    "        #2018 partisan lean\n",
    "        #get the current state abbreviation\n",
    "        current_state = row_series['state']\n",
    "        #get the lean of that state \n",
    "        state_lean_2018 = state_lean.loc[state_lean['abbreviation'] == current_state, '2018'].iloc[0]\n",
    "        all_data.at[index_label , 'partisan_lean_2018'] = state_lean_2018\n",
    "        #2020 partisan lean\n",
    "        state_lean_2020 = state_lean.loc[state_lean['abbreviation'] == current_state, '2020'].iloc[0]\n",
    "        all_data.at[index_label , 'partisan_lean_2020'] = state_lean_2020\n",
    "        \n",
    "    #house uses district lean\n",
    "    if all_data.at[index_label, 'type'] == 'rep':\n",
    "        #get the district and state\n",
    "        current_dist = row_series['full_district']\n",
    "        current_state = row_series['state']\n",
    "        #print(current_state)\n",
    "        if current_state in states:\n",
    "            #print(current_dist)\n",
    "            #get the lean\n",
    "            dist_lean_2018 = district_lean.loc[district_lean['district'] == current_dist, '2018'].iloc[0]\n",
    "            #add it\n",
    "            all_data.at[index_label , 'partisan_lean_2018'] = dist_lean_2018\n",
    "            #rinse and repeat for 2020\n",
    "            dist_lean_2020 = district_lean.loc[district_lean['district'] == current_dist, '2020'].iloc[0]\n",
    "            all_data.at[index_label , 'partisan_lean_2020'] = dist_lean_2020\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index_label, row_series in all_data.iterrows():\n",
    "    #use the bioguide_id to match (bioguide id is a number from govtrack that lets us match unique members)\n",
    "    id_code = row_series['bioguide_id']\n",
    "    state = row_series['state']\n",
    "    #get the lean of that state \n",
    "    twitter_url = twitter_handles.loc[twitter_handles['bioguide_id'] == id_code, 'twitter_url'].iloc[0]\n",
    "    #try to catch for NaN\n",
    "    try:\n",
    "        personal_twitter = re.sub(r'https:\\/\\/twitter.com\\/', \"\", twitter_url,)\n",
    "    except:\n",
    "        #print(\"no twitter!\")\n",
    "        personal_twitter = \"NaN\"\n",
    "\n",
    "    all_data.at[index_label , 'personal_twitter'] = personal_twitter\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-563b6d345aa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'project_data.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'all_data' is not defined"
     ]
    }
   ],
   "source": [
    "#write data to project data\n",
    "all_data.to_csv('project_data.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
